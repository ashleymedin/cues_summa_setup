{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the CUES SUMMA setup\n",
    "This notebook includes background and instructions on using `pysumma` to interactively run and manipulate SUMMA simulations.\n",
    "The example SUMMA setup included is for the CUES Snow Science Laboratory, a site located in the Sierra Nevada mountains.\n",
    "For more information about the CUES site, [visit their website](https://snow.ucsb.edu/). \n",
    "To begin, we have to regionalize the paths in the configuration files that SUMMA will use.\n",
    "This is accomplished by running a shell command. This is done by starting a line with the `!` operator.\n",
    "We simply run a script to complete the installation.\n",
    "Then, we can import some basic libraries along with `pysumma`.\n",
    "The `%pylab inline` magic command simply imports some standard scientific packages such as `numpy` and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./install_local_setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pysumma as ps\n",
    "import xarray as xr\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Interacting with SUMMA via the `Simulation` object\n",
    "## Instantiating a `Simulation` object\n",
    "\n",
    "To set up a `Simulation` object you must supply 2 pieces of information. \n",
    "\n",
    "First, the SUMMA executable; this could be either the compiled executable on your local machine, or a docker image. \n",
    "For this case, I'll assume that `summa.exe` is on your path. \n",
    "See the commented out `executable` for example of how you could also define the docker image. \n",
    "The string for the docker image simply came from looking at the output of the `docker images` command.\n",
    "\n",
    "The second piece of information is the path to the file manager, which we just created through the install script.\n",
    "To create the `Simulation` object you can then just pass these to the constructor as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable = '/pool0/data/andrbenn/summa/bin/summa.exe'\n",
    "#executable = 'docker.io/bartnijssen/summa:develop'\n",
    "file_manager = './file_manager.txt'\n",
    "\n",
    "s = ps.Simulation(executable, file_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Manipulating the configuration of the simulation object\n",
    "\n",
    "Most of your interactions with pysumma will be facilitated through this `Simulation` object, so let's take some time to look through what is in it. \n",
    "What's contained in the `Simulation` object right after instantiation is generally just the input required for a SUMMA run.\n",
    "For a more in depth discussion of what these are see the [SUMMA Input](https://summa.readthedocs.io/en/latest/input_output/SUMMA_input/) page of the documentation.\n",
    "There are several attributes of interest that can be examined. \n",
    "To see each of them you can simply `print` them. \n",
    "Here's a very high level overview of what's available:\n",
    "\n",
    "* `s.manager` - the file manager\n",
    "* `s.decisions` - the decisions file\n",
    "* `s.output_control` - defines what variables to write out\n",
    "* `s.force_file_list` - a listing of all of the forcing files to use\n",
    "* `s.local_attributes` - describes GRU/HRU attributes (lat, lon, elevation, etc)\n",
    "* `s.local_param_info` - listing of spatially constant local (HRU) parameter values\n",
    "* `s.basin_param_info` - listing of spatially constant basin (GRU) parameter values\n",
    "* `s.parameter_trial` - spatially distributed parameter values (will overwrite `local_param_info` values, can be either HRU or GRU)\n",
    "\n",
    "Most of these objects have a similar interface defined, with exceptions being `local_attributes` and `parameter_trial`. Those two are standard `xarray` datasets. All others follow the simple API:\n",
    "\n",
    "```\n",
    "print(x)                   # Show the data as SUMMA reads it\n",
    "x.get_option(NAME)         # Get an option\n",
    "x.set_option(NAME, VALUE)  # Change an option\n",
    "x.remove_option(NAME)      # Remove an option\n",
    "```\n",
    "\n",
    "More intuitively, you can use `key` - `value` type indexing like dictionaries, dataframes, and datasets:\n",
    "\n",
    "```\n",
    "print(x['key'])    # Get an option\n",
    "x['key'] = value   # Change an option\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting decisions\n",
    "\n",
    "So, now that we've got a handle on what's available and what you can do with it, let's actually try some of this out. First let's just print out our decisions file so we can see what's in the defaults.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.decisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "Great, we can see what's in there. But to be able to change anything we need to know the available options for each decision. Let's look at how to do that. For arbitrary reasons we will look at the `snowIncept` option, which describes the parameterization for snow interception in the canopy. First we will get it from the `decisions` object directly, and then query what it can be changed to, then finally change the value to something else.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just the `snowIncept` option\n",
    "print(s.decisions['snowIncept'])\n",
    "\n",
    "# Look at what we can set it to\n",
    "print(s.decisions['snowIncept'].available_options)\n",
    "\n",
    "# Change the value \n",
    "s.decisions['snowIncept'] = 'stickySnow'\n",
    "print(s.decisions['snowIncept'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Changing parameters\n",
    "\n",
    "Much like the decisions we can manipulate the `local_param_info` file. First, let's look at what's contained in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.local_param_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "Yikes, that's pretty long. \n",
    "One thing that's important to know is that only the first value is used by SUMMA.\n",
    "The other two columns of values are supposed to represent reasonable ranges for auto-calibration, but this feature is not yet implemented.\n",
    "For now we can ignore the right two columns.\n",
    "Like the decisions we can change things. See:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print it\n",
    "print(s.local_param_info['albedoMax'])\n",
    "\n",
    "# Change the value\n",
    "s.local_param_info['albedoMax'] = 0.7\n",
    "print(s.local_param_info['albedoMax'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Modifying output\n",
    "And one more, we can also modify what get's written to output. \n",
    "The output control file represents the options available through columns of numeric values.\n",
    "These numbers represent how to write the output. \n",
    "From the SUMMA documentation they are arranged as:\n",
    "\n",
    "```\n",
    "! varName          | outFreq | inst | sum | mean | var | min | max | mode\n",
    "```\n",
    "\n",
    "As before, let's look at what's in the `output_control` by simply printing it out.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.output_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Then, we can modify values by specifying a list of values corresponding to each of the columns\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just change the frequency to daily output\n",
    "print(s.output_control['scalarNetRadiation'])\n",
    "\n",
    "# Change the output statistic from hourly instantaneous to daily total\n",
    "s.output_control['scalarNetRadiation'] = [24, 1, 0, 0, 0, 0, 0, 0]\n",
    "print(s.output_control['scalarNetRadiation'])\n",
    "\n",
    "# Change it back\n",
    "s.output_control['scalarNetRadiation'] = [1, 0, 1, 0, 0, 0, 0, 0]\n",
    "print(s.output_control['scalarNetRadiation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Running pysumma and manipulating output\n",
    "\n",
    "Now that you've had an overview of how you can interact with SUMMA configurations through pysumma let's run a simulation. \n",
    "After running the simulation, we will make sure that it completed successfully by checking the status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.run('local', run_suffix='_default')\n",
    "assert s.status == 'Success'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "You can view the standard output and error of the simulation with the `s.stdout` and `s.stderr` if you ever encounter any issues. They should be `print`'ed to render the newlines correctly. I only print out the last portion here for simplicity. You should see `FORTRAN STOP: finished simulation successfully.` if all is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.stdout[-780:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "With a complete run, we can look at the output simply by using the simulation's `output` attribute.\n",
    "It is simply an xarray dataset, which can be manipulated in all of the usual ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = xr.open_dataset('./validation/cues_2011-2019.nc')\n",
    "obs = obs.sel(time=s.output.time, method='nearest')\n",
    "s.output['scalarSWE'].plot(label='SUMMA')\n",
    "obs['swe'].plot(label='Observation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(100 * s.output['scalarSnowDepth']).plot(label='SUMMA') # Convert to cm\n",
    "obs['snow_depth'].plot(label='Observation')\n",
    "plt.ylabel('Snow depth [cm]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the snow layering\n",
    "\n",
    "In this example we will change the snow layering scheme so that only a maximum of 2 layers will ever exist. We do this by making it so that the amount of snow needed to split layers is very large. We will also make sure we are using the `CLM_2010` snow layering scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_2layer = ps.Simulation(executable, file_manager)\n",
    "s_2layer.decisions['snowLayers']  = 'CLM_2010'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No 3rd, 4th, and 5th layers until > 100 meters of snow (AKA never)\n",
    "s_2layer.local_param_info['zminLayer3'] = 100.\n",
    "s_2layer.local_param_info['zminLayer4'] = 100.\n",
    "s_2layer.local_param_info['zminLayer5'] = 100.\n",
    "s_2layer.local_param_info['zmaxLayer2_lower'] = 9000.\n",
    "s_2layer.local_param_info['zmaxLayer3_lower'] = 9000.\n",
    "s_2layer.local_param_info['zmaxLayer4_lower'] = 9000.\n",
    "s_2layer.local_param_info['zmaxLayer2_upper'] = 9000.\n",
    "s_2layer.local_param_info['zmaxLayer3_upper'] = 9000.\n",
    "s_2layer.local_param_info['zmaxLayer4_upper'] = 9000.\n",
    "\n",
    "# Set the top layer to grow to a maximum of 25 cm before the second layer is created\n",
    "s_2layer.local_param_info['zminLayer1'] = 0.0075\n",
    "s_2layer.local_param_info['zmaxLayer1_lower'] = 0.250\n",
    "s_2layer.local_param_info['zmaxLayer1_upper'] = 0.250\n",
    "\n",
    "# If there's no error, the layer parameters are good to go\n",
    "s_2layer.validate_layer_params(s.local_param_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_2layer.run('local', run_suffix='_2layer')\n",
    "assert s_2layer.status == 'Success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_2layer.output['scalarSWE'].plot(label='SUMMA 2 Layer')\n",
    "s.output['scalarSWE'].plot(label='SUMMA default')\n",
    "obs['swe'].plot(label='Observation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some fancy plotting capabilities\n",
    "\n",
    "Now, we see that the above gives different results but we can't quite see that the 2 layer model has only 2 layers.\n",
    "To verify this we can plot the layer temperature through time.\n",
    "We can also do this for the original 5 layer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_2l = s_2layer.output['mLayerTemp'].sel(hru=1)\n",
    "depth_2l = s_2layer.output['iLayerHeight'].sel(hru=1)\n",
    "\n",
    "temp_5l = s.output['mLayerTemp'].sel(hru=1)\n",
    "depth_5l = s.output['iLayerHeight'].sel(hru=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(12, 9), sharex=True)\n",
    "\n",
    "axes[0].set_ylabel('Snow depth (m)')\n",
    "axes[0].set_title('2 Layer model')\n",
    "axes[1].set_ylabel('Snow depth (m)')\n",
    "axes[1].set_title('5 Layer model')\n",
    "ps.plotting.layers(temp_2l, depth_2l, ax=axes[0], variable_range=[260, 273])\n",
    "ps.plotting.layers(temp_5l, depth_5l, ax=axes[1], variable_range=[260, 273])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running ensembles of different decisions and/or parameters\n",
    "It would be cumbersome and time-consuming to create many different simulation objects and run them all separately.\n",
    "To facilitate faster exploration pysumma implements an `Ensemble` class which will manage simulations for you.\n",
    "et's create an ensemble of simulations that try out different values of the albedo decay rate.\n",
    "We will try out 4 values and run each of them in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_rates = {'albedoDecayRate': np.array([1.0e+5, 5.0e+5, 1.0e+6, 5.0e+6])}\n",
    "config = ps.ensemble.parameter_product(decay_rates)\n",
    "param_ens = ps.Ensemble(executable, config, file_manager, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this ensemble is similar to running a simulation.\n",
    "Following execution we will loop through each of the underlying simulations to make sure nothing went wrong.\n",
    "A note on the names: the ensemble uses `++` as a delimiter to create unique identifiers for each simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ens.run('local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = param_ens.summary()\n",
    "pprint(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went well, we will want to collect all of the output files into one nice dataset.\n",
    "Because each of the simulations was written to a separate output file we have to do this via the ensemble object.\n",
    "As you can see, in the merged output there is a new dimension labeled `albedoDecayRate`, which allows us to easily select out and analyze the data.\n",
    "For now, let's just plot the SWE for an arbitrary year for each of the runs to see what happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ds = param_ens.merge_output()\n",
    "param_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ds['scalarSWE'].sel(hru=1).plot.line(x='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all",
   "language": "python",
   "name": "all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
